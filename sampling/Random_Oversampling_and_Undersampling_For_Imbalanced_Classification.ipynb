{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8904a223",
   "metadata": {},
   "source": [
    "[Reference](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d2f46",
   "metadata": {},
   "source": [
    "**Parts**\n",
    "1. Random Resampling Imbalanced Datasets\n",
    "2. Imbalanced-Learn Library\n",
    "3. Random Oversampling Imbalanced Datasets\n",
    "4. Random Undersampling Imbalanced Datasets\n",
    "5. Combining Random Oversampling and Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295cee05",
   "metadata": {},
   "source": [
    "[Random resampling]\n",
    "\n",
    "Random Oversampling: Randomly duplicate examples in the minority class.\n",
    "\n",
    "Random Undersampling: Randomly delete examples in the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ddc52",
   "metadata": {},
   "source": [
    "[Good]\n",
    "\n",
    "They are referred to as “naive resampling” methods because they assume nothing about the data and no heuristics are used. \n",
    "\n",
    "This makes them simple to implement and fast to execute, which is desirable for very large and complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a525e3b",
   "metadata": {},
   "source": [
    "### Resampling - Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "498fdc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m pip install imbalanced-learn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10c8e956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]data:  (569, 30)\n",
      "[*]target:  (569,)\n",
      ">>1:  357\n",
      ">>0:  212\n"
     ]
    }
   ],
   "source": [
    "data_cancer = load_breast_cancer()\n",
    "X = data_cancer['data']\n",
    "target = data_cancer['target']\n",
    "print(\"[*]data: \", X.shape)\n",
    "print(\"[*]target: \", target.shape)\n",
    "print(\">>1: \", sum(target==1))\n",
    "print(\">>0: \", sum(target==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7003746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Delete part of 0 data to make imbalanced data\n",
      "[*]data:  (387, 30)\n",
      "[*]target:  (387,)\n",
      ">>1:  357\n",
      ">>0:  30\n"
     ]
    }
   ],
   "source": [
    "print(\"[*]Delete part of 0 data to make imbalanced data\")\n",
    "zero_idx = np.where(target==0)\n",
    "zero_idx_deleted = list(zero_idx[0])[30:]\n",
    "new_X = np.delete(X, zero_idx_deleted, axis=0)\n",
    "new_target = np.delete(target, zero_idx_deleted)\n",
    "print(\"[*]data: \", new_X.shape)\n",
    "print(\"[*]target: \", new_target.shape)\n",
    "print(\">>1: \", sum(new_target==1))\n",
    "print(\">>0: \", sum(new_target==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28b42ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]After oversampling strategy 'minority'\n",
      "X_over:  (714, 30)\n",
      "y_over:  (714,)\n",
      ">>1:  357\n",
      ">>0:  357\n"
     ]
    }
   ],
   "source": [
    "from imblearn import over_sampling\n",
    "\n",
    "\n",
    "oversample = over_sampling.RandomOverSampler(sampling_strategy='minority')\n",
    "X_over, y_over = oversample.fit_resample(new_X, new_target)\n",
    "print(\"[*]After oversampling strategy 'minority'\")\n",
    "print(\"X_over: \", X_over.shape)\n",
    "print(\"y_over: \", y_over.shape)\n",
    "print(\">>1: \", sum(y_over==1))\n",
    "print(\">>0: \", sum(y_over==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "952a3844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]After oversampling strategy 'minority'\n",
      "X_over:  (535, 30)\n",
      "y_over:  (535,)\n",
      ">>1:  357\n",
      ">>0:  178\n"
     ]
    }
   ],
   "source": [
    "oversample = over_sampling.RandomOverSampler(sampling_strategy=0.5)\n",
    "X_over, y_over = oversample.fit_resample(new_X, new_target)\n",
    "print(\"[*]After oversampling strategy 'minority'\")\n",
    "print(\"X_over: \", X_over.shape)\n",
    "print(\"y_over: \", y_over.shape)\n",
    "print(\">>1: \", sum(y_over==1))\n",
    "print(\">>0: \", sum(y_over==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33a449e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]dataset\n",
      ">>X:  (10000, 20)\n",
      ">>y: \n",
      "Counter({0: 9900, 1: 100})\n",
      "[*]dataset - after fit_resample\n",
      ">>y: \n",
      "Counter({0: 9900, 1: 9900})\n"
     ]
    }
   ],
   "source": [
    "# example of random oversampling to balance the class distribution\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\n",
    "print(\"[*]dataset\")\n",
    "print(\">>X: \", X.shape)\n",
    "print(\">>y: \")\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y))\n",
    "\n",
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# fit and apply the transform\n",
    "print(\"[*]dataset - after fit_resample\")\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "\n",
    "# summarize class distribution\n",
    "print(\">>y: \")\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12cb3c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.988\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# define pipeline\n",
    "steps = [('over', RandomOverSampler()), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec4ea4",
   "metadata": {},
   "source": [
    "### Resampling - UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "69b34a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Delete part of 0 data to make imbalanced data\n",
      "[*]data:  (387, 30)\n",
      "[*]target:  (387,)\n",
      ">>1:  357\n",
      ">>0:  30\n"
     ]
    }
   ],
   "source": [
    "print(\"[*]Delete part of 0 data to make imbalanced data\")\n",
    "zero_idx = np.where(target==0)\n",
    "zero_idx_deleted = list(zero_idx[0])[30:]\n",
    "new_X = np.delete(X, zero_idx_deleted, axis=0)\n",
    "new_target = np.delete(target, zero_idx_deleted)\n",
    "print(\"[*]data: \", new_X.shape)\n",
    "print(\"[*]target: \", new_target.shape)\n",
    "print(\">>1: \", sum(new_target==1))\n",
    "print(\">>0: \", sum(new_target==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b5b480c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]After oversampling strategy 'majority'\n",
      "X_over:  (60, 30)\n",
      "y_over:  (60,)\n",
      ">>1:  30\n",
      ">>0:  30\n"
     ]
    }
   ],
   "source": [
    "from imblearn import under_sampling\n",
    "\n",
    "\n",
    "oversample = under_sampling.RandomUnderSampler(sampling_strategy='majority')\n",
    "X_over, y_over = oversample.fit_resample(new_X, new_target)\n",
    "print(\"[*]After undersampling strategy 'majority'\")\n",
    "print(\"X_over: \", X_over.shape)\n",
    "print(\"y_over: \", y_over.shape)\n",
    "print(\">>1: \", sum(y_over==1))\n",
    "print(\">>0: \", sum(y_over==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f78224db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]dataset\n",
      ">>X:  (10000, 20)\n",
      ">>y: \n",
      "Counter({0: 9900, 1: 100})\n",
      "[*]dataset - after fit_resample\n",
      ">>y: \n",
      "Counter({0: 100, 1: 100})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\n",
    "print(\"[*]dataset\")\n",
    "print(\">>X: \", X.shape)\n",
    "print(\">>y: \")\n",
    "\n",
    "# summarize class distribution\n",
    "\n",
    "print(Counter(y))\n",
    "# define undersample strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "# fit and apply the transform\n",
    "X_over, y_over = undersample.fit_resample(X, y)\n",
    "\n",
    "# summarize class distribution\n",
    "print(\"[*]dataset - after fit_resample\")\n",
    "print(\">>y: \")\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66f45e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.870\n"
     ]
    }
   ],
   "source": [
    "# example of evaluating a decision tree with random undersampling\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\n",
    "\n",
    "# define pipeline\n",
    "steps = [('under', RandomUnderSampler()), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e63b11",
   "metadata": {},
   "source": [
    "### Oversampling + Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e9e2b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.993\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\n",
    "\n",
    "# define pipeline\n",
    "over = RandomOverSampler(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under), ('m', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f43c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
